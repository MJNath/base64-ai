{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7b57516",
   "metadata": {},
   "source": [
    "## LangChain Expression Language (LCEL)\n",
    "\n",
    "LCEL (LangChain Expression Language) est un langage déclaratif et composable conçu pour orchestrer des chaînes de traitement avec des LLM (Large Language Models). Il permet de composer des chaînes d'étapes (prompts, modèles, outils, fonctions, etc.) de manière lisible, modulaire et facilement testable.\n",
    "\n",
    "### Objectif\n",
    "Faciliter la création de pipelines LLM complexes en combinant différentes composantes (prompts, modèles, outils, formatteurs) sans écrire trop de logique impérative.\n",
    "\n",
    "### Principes clés\n",
    "\n",
    "- Composable : chaque composant peut être combiné avec d'autres via des opérateurs (|, +, etc.).\n",
    "- Lisible : syntaxe proche d’un pipeline, facile à comprendre.\n",
    "- Testable : chaque étape peut être testée indépendamment.\n",
    "- Réutilisable : permet d'encapsuler des chaînes en sous-composants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427274ee",
   "metadata": {},
   "source": [
    "### Exécution par séquence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableSequence, RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence, RunnableParallel\n",
    "from langchain_core.tools import tool\n",
    "import random\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "@tool\n",
    "def execute_sql(code : str) -> str :\n",
    "    \"\"\"\n",
    "    Cette fonction permet d'executer le code sql passer comme argument\n",
    "    \"\"\"\n",
    "    print(\"----execution de l'outil en cours....\")\n",
    "    x = random.randint(0,10)\n",
    "    cond = x % 2\n",
    "\n",
    "    if cond == 0:\n",
    "        return \"le code s'est exécuté correctement.\"\n",
    "    else :\n",
    "        return \"le code n'est pas correct.\"\n",
    "\n",
    "\n",
    "def sql_translator(input, instructions):\n",
    "\n",
    "    chat_model= ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "    llm_with_tool = chat_model.bind_tools([execute_sql])\n",
    "\n",
    "    prompt= ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\" , f\"{instructions}\"),\n",
    "            (\"human\" , \"{input}\")  \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = RunnableSequence(prompt, llm_with_tool)\n",
    "    call = chain.invoke(input)\n",
    "    if call.content:\n",
    "        return call.content\n",
    "    return call.additional_kwargs\n",
    "\n",
    "\n",
    "instruction =\"\"\"\n",
    "Tu es un traducteur de texte en sql ou de sql en texte. \n",
    "Tu prends les instructions données en languages \n",
    "naturel pour les traduit en code sql ou du code sql en language naturel.\n",
    "renvoie uniquement la traduction et ne fait pas la conversation.\n",
    "\n",
    "Lorsque l'utilisateur te donne un code sql pour traduire en texte\n",
    "execute le d'abord pour savoir si le code est correct ou pas en faisant appel\n",
    "à l'outil \"execute_sql\".\n",
    "\"\"\"\n",
    "input = \"\"\"\n",
    "SELECT\n",
    "  e.id,\n",
    "  e.first_name,\n",
    "  e.last_name,\n",
    "  qs.q4_2022-qs.q3_2022 AS sales_change\n",
    "FROM employees e\n",
    "JOIN quarterly_sales qs\n",
    "ON e.id = qs.employee_id\n",
    "WHERE qs.q4_2022-qs.q3_2022 < 0;\n",
    "\"\"\"\n",
    "print(sql_translator(input, instruction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1df79a",
   "metadata": {},
   "source": [
    "### Exécution parallèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction2= \"\"\"\n",
    "Tu es Saray, une agente commmerciale de chez Nodes United Bank.\n",
    "Tu es responsable des offres commerciales. Lorsque le client te donne son nom complet,\n",
    "verifie s'il est éligible à la promotion en utilisant l'outil searchEliblige\n",
    "\"\"\"\n",
    "instruction = \"\"\"\n",
    "Tu es Otniel, un agent du service de dette de chez Nodes United Bank.\n",
    "Tu es responsable des crédit. Lorsque le client te donne son nom complet,\n",
    "verifie s'il doit la banque en utilisant l'outil searchDettes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd8b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_Qxhv0013oBTc11jHMcvqF0fQ', 'function': {'arguments': '{\"nom\":\"Nkodia\",\"prenom\":\"Alice\"}', 'name': 'searchDettes'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 67, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-BaOV9B5t7ArNLHvkKvRIq52OczY9B', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--0b41b100-195c-46f7-8443-7d829852f380-0' tool_calls=[{'name': 'searchDettes', 'args': {'nom': 'Nkodia', 'prenom': 'Alice'}, 'id': 'call_Qxhv0013oBTc11jHMcvqF0fQ', 'type': 'tool_call'}] usage_metadata={'input_tokens': 67, 'output_tokens': 20, 'total_tokens': 87, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "-----------------\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_ftLGd7BPSPHYm2cnBalgIAuB', 'function': {'arguments': '{\"nom\":\"Nkodia\",\"prenom\":\"Alice\"}', 'name': 'searchEliblige'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 73, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BaOV9ttAEwqXGcfKwlk2aSYas1BeQ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--c944d7db-6fa7-4aa3-906d-76943768d2f8-0' tool_calls=[{'name': 'searchEliblige', 'args': {'nom': 'Nkodia', 'prenom': 'Alice'}, 'id': 'call_ftLGd7BPSPHYm2cnBalgIAuB', 'type': 'tool_call'}] usage_metadata={'input_tokens': 73, 'output_tokens': 21, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence, RunnableParallel\n",
    "from langchain_core.tools import tool\n",
    "import pandas as pd\n",
    "\n",
    "@tool\n",
    "def searchEliblige(nom : str,prenom : str) -> dict | str:\n",
    "\n",
    "    \"\"\"\n",
    "    Cette fonction permet de rechercher les clients qui sont éligibles aux offres promotionnelles.\n",
    "    \"\"\"\n",
    "    df=pd.read_csv(\"/workspaces/base64-ai/data/clients_eligibles.csv\")\n",
    "    cond = df['nom'] == nom.lower().capitalize()\n",
    "    cond2 = df['prénom'] == prenom.lower().capitalize()\n",
    "\n",
    "    if df.loc[cond].empty==False and df.loc[cond2].empty==False :\n",
    "        return {\"fullname\" : f\"{prenom} {nom}\", \"L'indentifiant\" : f\"{df.loc[cond]['client_id'].values[0]}\",\"Eligible  Promo\" :True}\n",
    "    return \"le client n'existe pas\"\n",
    "\n",
    "@tool\n",
    "def searchDettes(nom : str,prenom : str) -> dict | str:\n",
    "    \"\"\"\n",
    "    Cette fonction permet de rechercher les clients qui sont débiteurs.\n",
    "    \"\"\"\n",
    "    df=pd.read_csv(\"/workspaces/base64-ai/data/clients_debiteurs.csv\")\n",
    "    cond = df['nom'] == nom.lower().capitalize()\n",
    "    cond2 = df['prénom'] == prenom.lower().capitalize()\n",
    "\n",
    "    if df.loc[cond].empty==False and df.loc[cond2].empty==False :\n",
    "        return {\"fullname\" : f\"{prenom} {nom}\", \"L'indentifiant\" : f\"{df.loc[cond]['client_id'].values[0]}\",\"dette\" :True}\n",
    "    return \"le client n'existe pas\"\n",
    "\n",
    "\n",
    "\n",
    "# Premier niveau d'abstraction qui est le model\n",
    "llm = init_chat_model(model=\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "llm_dette = llm.bind_tools([searchDettes])\n",
    "llm_com = llm.bind_tools([searchEliblige])\n",
    "\n",
    "\n",
    "# Deuxieme niveau d'abstraction qui represente les messages\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", f\"{instruction}\"),\n",
    "        (\"human\", \"{content}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent_dette = prompt | llm_dette\n",
    "\n",
    "prompt2= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", f\"{instruction2}\"),\n",
    "        (\"human\" , \"{input}\")\n",
    "    ]\n",
    ")\n",
    "agent_commercial= RunnableSequence(prompt,llm_com)\n",
    "\n",
    "\n",
    "team = RunnableParallel({\n",
    "    \"agent_dette\":agent_dette,\n",
    "    \"agent_com\":agent_commercial\n",
    "})\n",
    "\n",
    "\n",
    "call = team.invoke(\"Nkodia Alice\")\n",
    "print(call[\"agent_dette\"])\n",
    "print('-----------------')\n",
    "print(call[\"agent_com\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ba967",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Message dict must contain 'role' and 'content' keys, got {'content': 'Nkodia Alice'}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/MESSAGE_COERCION_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/workspaces/base64-ai/env/lib/python3.12/site-packages/langchain_core/messages/utils.py:329\u001b[0m, in \u001b[0;36m_convert_to_message\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 329\u001b[0m     msg_type \u001b[38;5;241m=\u001b[39m \u001b[43mmsg_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'role'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/workspaces/base64-ai/env/lib/python3.12/site-packages/langchain_core/messages/utils.py:331\u001b[0m, in \u001b[0;36m_convert_to_message\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     msg_type \u001b[38;5;241m=\u001b[39m \u001b[43mmsg_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# None msg content is not allowed\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprebuilt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_react_agent\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m create_react_agent(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m'\u001b[39m, tools\u001b[38;5;241m=\u001b[39m[searchDettes], prompt\u001b[38;5;241m=\u001b[39mprompt)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNkodia Alice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/base64-ai/env/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2894\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2891\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2892\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2894\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2895\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2898\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2899\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2900\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2903\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2906\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2907\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2908\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m:=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   2909\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/workspaces/base64-ai/env/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2524\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2518\u001b[0m     get_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m-> 2524\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_channels\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2525\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[1;32m   2526\u001b[0m         loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/workspaces/base64-ai/env/lib/python3.12/site-packages/langgraph/pregel/loop.py:494\u001b[0m, in \u001b[0;36mPregelLoop.tick\u001b[0;34m(self, input_keys)\u001b[0m\n\u001b[1;32m    484\u001b[0m     print_step_writes(\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep,\n\u001b[1;32m    486\u001b[0m         writes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    491\u001b[0m         ),\n\u001b[1;32m    492\u001b[0m     )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# all tasks have finished\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m mv_writes, updated_channels \u001b[38;5;241m=\u001b[39m \u001b[43mapply_writes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpointer_get_next_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# apply writes to managed values\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m mv_writes\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/workspaces/base64-ai/env/lib/python3.12/site-packages/langgraph/pregel/algo.py:322\u001b[0m, in \u001b[0;36mapply_writes\u001b[0;34m(checkpoint, channels, tasks, get_next_version, trigger_to_nodes)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chan, vals \u001b[38;5;129;01min\u001b[39;00m pending_writes_by_channel\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chan \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[0;32m--> 322\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchan\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m get_next_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m             checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m][chan] \u001b[38;5;241m=\u001b[39m get_next_version(\n\u001b[1;32m    324\u001b[0m                 max_version,\n\u001b[1;32m    325\u001b[0m                 channels[chan],\n\u001b[1;32m    326\u001b[0m             )\n\u001b[1;32m    327\u001b[0m             \u001b[38;5;66;03m# unavailable channels can't trigger tasks, so don't add them\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/base64-ai/env/lib/python3.12/site-packages/langgraph/channels/binop.py:91\u001b[0m, in \u001b[0;36mBinaryOperatorAggregate.update\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m     89\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m values:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/base64-ai/env/lib/python3.12/site-packages/langgraph/graph/message.py:38\u001b[0m, in \u001b[0;36m_add_messages_wrapper.<locals>._add_messages\u001b[0;34m(left, right, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_add_messages\u001b[39m(\n\u001b[1;32m     35\u001b[0m     left: Optional[Messages] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, right: Optional[Messages] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     36\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Messages, Callable[[Messages, Messages], Messages]]:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify non-null arguments for both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceived: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mleft\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m         )\n",
      "File \u001b[0;32m/workspaces/base64-ai/env/lib/python3.12/site-packages/langgraph/graph/message.py:181\u001b[0m, in \u001b[0;36madd_messages\u001b[0;34m(left, right, format)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# coerce to message\u001b[39;00m\n\u001b[1;32m    175\u001b[0m left \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    176\u001b[0m     message_chunk_to_message(cast(BaseMessageChunk, m))\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m convert_to_messages(left)\n\u001b[1;32m    178\u001b[0m ]\n\u001b[1;32m    179\u001b[0m right \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    180\u001b[0m     message_chunk_to_message(cast(BaseMessageChunk, m))\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mconvert_to_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m ]\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# assign missing ids\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m left:\n",
      "File \u001b[0;32m/workspaces/base64-ai/env/lib/python3.12/site-packages/langchain_core/messages/utils.py:367\u001b[0m, in \u001b[0;36mconvert_to_messages\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(messages, PromptValue):\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m messages\u001b[38;5;241m.\u001b[39mto_messages()\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43m_convert_to_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n",
      "File \u001b[0;32m/workspaces/base64-ai/env/lib/python3.12/site-packages/langchain_core/messages/utils.py:339\u001b[0m, in \u001b[0;36m_convert_to_message\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    335\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage dict must contain \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keys, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m         msg \u001b[38;5;241m=\u001b[39m create_message(\n\u001b[1;32m    337\u001b[0m             message\u001b[38;5;241m=\u001b[39mmsg, error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mMESSAGE_COERCION_FAILURE\n\u001b[1;32m    338\u001b[0m         )\n\u001b[0;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     _message \u001b[38;5;241m=\u001b[39m _create_message_from_message_type(\n\u001b[1;32m    341\u001b[0m         msg_type, msg_content, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmsg_kwargs\n\u001b[1;32m    342\u001b[0m     )\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Message dict must contain 'role' and 'content' keys, got {'content': 'Nkodia Alice'}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/MESSAGE_COERCION_FAILURE "
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "x = create_react_agent(model='gpt-4o-mini', tools=[searchDettes], prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3eb583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
