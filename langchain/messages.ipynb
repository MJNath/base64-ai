{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3765c6a6",
   "metadata": {},
   "source": [
    "# Le Concept de Messages\n",
    "\n",
    "Les *messages* représentent des échanges structurés dans une conversation entre un utilisateur, un agent IA, ou des outils externes. C’est une abstraction clé pour travailler efficacement avec des modèles de type **Grands Modèles de Languages**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Pourquoi structurer les messages ?\n",
    "\n",
    "Structurer les échanges en objets `Message` permet de :\n",
    "\n",
    "- ✅ Maintenir l’historique contextuel de manière organisée.\n",
    "- ✅ Définir le rôle de chaque message (utilisateur, IA, système, etc.).\n",
    "- ✅ Faciliter la gestion de la mémoire conversationnelle.\n",
    "- ✅ Permettre l’intégration avec des outils ou des fonctions externes.\n",
    "- ✅ Créer des **agents intelligents** capables d'interagir, réfléchir et agir étape par étape.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Les types de messages\n",
    "\n",
    "| Type de Message     | Description                                                                 |\n",
    "|---------------------|-----------------------------------------------------------------------------|\n",
    "| `SystemMessage`     | Instructions initiales données à l’IA (définition du rôle, ton, etc.)       |\n",
    "| `HumanMessage`      | Message envoyé par l’utilisateur humain.                                    |\n",
    "| `AIMessage`         | Réponse générée par le modèle IA.                                           |\n",
    "| `FunctionMessage`   | Résultat d’un appel de fonction exécuté par le modèle.                      |\n",
    "| `ToolMessage`       | Message provenant d’un outil utilisé dans le cadre d’un agent.              |\n",
    "\n",
    "Chaque message peut contenir du **contenu** (texte, fonction, résultats), des **métadonnées**, et participer à une session enrichie et pilotable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757b7361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='5 fois 5 égale 25.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 23, 'total_tokens': 33, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BXppgYBjPepodyBxYB58Nr2pFhWgb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--d78fa472-9416-4b5a-b6fa-03eb8859e901-0' usage_metadata={'input_tokens': 23, 'output_tokens': 10, 'total_tokens': 33, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"tu est un assistant\"),\n",
    "    HumanMessage(content=\"fais 5 ffois 5\"),\n",
    "    # AIMessage(content=\"Très bien. Souhaitez-vous un hôtel ou une activité spécifique ?\")\n",
    "]\n",
    "\n",
    "llm = init_chat_model(model = \"gpt-4o-mini\" , model_provider=\"openai\")\n",
    "call = llm.invoke(messages)\n",
    "print(call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e158aeb5",
   "metadata": {},
   "source": [
    "### Personnalisation du comportement du modèle\n",
    "\n",
    "Une **hallucination** dans le contexte de l’intelligence artificielle désigne une réponse générée par le modèle qui semble plausible, mais qui est **fausse, inventée ou incohérente avec les données réelles**.\n",
    "\n",
    "Cela peut se produire lorsque le modèle :\n",
    "\n",
    "- ne dispose pas d’un contexte suffisant,\n",
    "- interprète mal une consigne,\n",
    "- ou tente de compléter une réponse sans disposer d'informations fiables.\n",
    "\n",
    "Un prompt bien conçu permet de :\n",
    "\n",
    "- **fournir un cadre clair** (ex. : \"réponds uniquement si tu connais la réponse\"),\n",
    "- **spécifier la source d’information** (ex. : \"utilise uniquement les données ci-dessous\"),\n",
    "- **imposer une structure** de réponse (tableau, JSON, résumé...),\n",
    "- **restreindre le domaine** de la réponse (ex. : \"ne parle que de la législation congolaise\").\n",
    "\n",
    "#### ✅ Exemple\n",
    "\n",
    "Prompt flou :\n",
    "> *\"Explique la législation sur les start-ups.\"*\n",
    "\n",
    "➡️ Réponse possible : mélange de lois de différents pays, imprécisions.\n",
    "\n",
    "Prompt guidé :\n",
    "> *\"Tu es un juriste congolais. Explique uniquement les lois en vigueur en République du Congo concernant la création de start-ups, en t’appuyant sur l’Acte uniforme OHADA.\"*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b6da9",
   "metadata": {},
   "source": [
    "### String PromptTemplates\n",
    "\n",
    "Ces modèles de prompts sont utilisés pour formater une seule chaîne de caractères et sont généralement utilisés pour des entrées plus simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50898b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Tu es un traducteur. Tu traduit le Bonjour en anglais')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Tu es un traducteur. Tu traduit le {contexte} en {langue}\")\n",
    "\n",
    "prompt_template.invoke({\"contexte\": \"Bonjour\", \"langue\" : \"anglais\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeaeeca",
   "metadata": {},
   "source": [
    "### ChatPromptTemplates\n",
    "\n",
    "Ces modèles d'invite sont utilisés pour formater une liste de messages. Ces « modèles » consistent en une liste de modèles eux-mêmes. Par exemple, une façon courante de construire et d'utiliser un ChatPromptTemplate est la suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc7063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Tu es un Rose, une slameuse', additional_kwargs={}, response_metadata={}), HumanMessage(content='Ecrit un texte de slam sur le amour', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"Tu es un Rose, une slameuse\"),\n",
    "    (\"user\", \"Ecrit un texte de slam sur le {sujet}\")\n",
    "])\n",
    "\n",
    "prompt_template.invoke({\"sujet\": \"amour\"})\n",
    "\n",
    "#Dans l'exemple ci-dessus, ce ChatPromptTemplate construira deux messages lorsqu'il sera appelé. Le premier est un message système, qui n'a aucune variable à formater. Le second est un HumanMessage, et sera formaté par la variable sujet transmise par l'utilisateur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70b83cb",
   "metadata": {},
   "source": [
    "### MessagesPlaceholder\n",
    "\n",
    "Ce prompt est chargé d'ajouter une liste de messages à un endroit particulier. Dans le modèle ChatPromptTemplate ci-dessus, nous avons vu comment nous pouvions formater deux messages, chacun étant une chaîne de caractères. Mais qu'en est-il si nous voulons que l'utilisateur transmette une liste de messages que nous placerons à un endroit particulier ? C'est ainsi que l'on utilise MessagesPlaceholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7895b585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Tu es un Rose, une slameuse', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"Tu es un Rose, une slameuse\"),\n",
    "    MessagesPlaceholder(\"Memoire\")\n",
    "])\n",
    "\n",
    "prompt_template.invoke({\"Memoire\": [HumanMessage(content=\"hi!\")]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
